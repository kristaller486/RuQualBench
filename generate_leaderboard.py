import json
import statistics
from pathlib import Path
from typing import Dict, List, Any
from collections import defaultdict
from datetime import datetime
from jinja2 import Environment, FileSystemLoader


def parse_logs(logs_dir: Path) -> Dict[str, List[Dict[str, Any]]]:
    """–ü–∞—Ä—Å–∏—Ç –≤—Å–µ JSON –ª–æ–≥–∏ –∏ –≥—Ä—É–ø–ø–∏—Ä—É–µ—Ç –ø–æ –º–æ–¥–µ–ª—è–º"""
    models_data = defaultdict(list)
    
    for log_file in logs_dir.glob("*.json"):
        try:
            with open(log_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            config = data.get("config", {})
            summary = data.get("summary", {})
            
            model_name = config.get("model", "Unknown")
            verbose_name = config.get("verbose_name")
            display_name = verbose_name if verbose_name else model_name
            
            critical = summary.get("critical_mistakes_per_1000_tokens", 0)
            mistakes = summary.get("mistakes_per_1000_tokens", 0)
            additional = summary.get("additional_mistakes_per_1000_tokens", 0)
            normalized_total = critical * 2 + mistakes + additional * 0.5

            models_data[display_name].append({
                "critical": critical,
                "mistakes": mistakes,
                "additional": additional,
                "total": normalized_total,
                "tokens": summary.get("total_tokens", 0),
                "file": log_file.name
            })
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ {log_file}: {e}")
            continue
    
    return models_data


def aggregate_model_data(runs: List[Dict[str, Any]]) -> Dict[str, Any]:
    """–ê–≥—Ä–µ–≥–∏—Ä—É–µ—Ç –¥–∞–Ω–Ω—ã–µ –¥–ª—è –º–æ–¥–µ–ª–∏ —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ –ø—Ä–æ–≥–æ–Ω–∞–º–∏"""
    if len(runs) == 1:
        return {
            **runs[0],
            "num_runs": 1,
            "critical_se": None,
            "mistakes_se": None,
            "additional_se": None,
            "total_se": None
        }
    
    critical_values = [r["critical"] for r in runs]
    mistakes_values = [r["mistakes"] for r in runs]
    additional_values = [r["additional"] for r in runs]
    total_values = [r["total"] for r in runs]
    tokens_values = [r["tokens"] for r in runs]
    
    def calc_se(values):
        if len(values) < 2:
            return 0
        stdev = statistics.stdev(values)
        return stdev / (len(values) ** 0.5)
    
    return {
        "critical": round(statistics.mean(critical_values), 2),
        "critical_se": round(calc_se(critical_values), 2) if len(runs) >= 2 else None,
        "mistakes": round(statistics.mean(mistakes_values), 2),
        "mistakes_se": round(calc_se(mistakes_values), 2) if len(runs) >= 2 else None,
        "additional": round(statistics.mean(additional_values), 2),
        "additional_se": round(calc_se(additional_values), 2) if len(runs) >= 2 else None,
        "total": round(statistics.mean(total_values), 2),
        "total_se": round(calc_se(total_values), 2) if len(runs) >= 2 else None,
        "tokens": int(statistics.mean(tokens_values)),
        "num_runs": len(runs),
        "file": runs[0]["file"]
    }


def generate_leaderboard():
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç HTML –ª–∏–¥–µ—Ä–±–æ—Ä–¥ –∏–∑ JSON –ª–æ–≥–æ–≤"""
    logs_dir = Path("logs")
    
    if not logs_dir.exists():
        print("–ü–∞–ø–∫–∞ logs/ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞!")
        return
    
    # –ü–∞—Ä—Å–∏–º –∏ –≥—Ä—É–ø–ø–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ
    print("–ü–∞—Ä—Å–∏–Ω–≥ JSON –ª–æ–≥–æ–≤...")
    models_data = parse_logs(logs_dir)
    
    if not models_data:
        print("–ù–µ –Ω–∞–π–¥–µ–Ω–æ –≤–∞–ª–∏–¥–Ω—ã—Ö JSON –ª–æ–≥–æ–≤!")
        return
    
    # –ê–≥—Ä–µ–≥–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏
    print("–ê–≥—Ä–µ–≥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö...")
    leaderboard = []
    for model_name, runs in models_data.items():
        aggregated = aggregate_model_data(runs)
        leaderboard.append({
            "model": model_name,
            **aggregated
        })
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –æ–±—â–µ–º—É –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –æ—à–∏–±–æ–∫ (–º–µ–Ω—å—à–µ = –ª—É—á—à–µ)
    leaderboard.sort(key=lambda x: x["total"])
    
    # –ù–∞—Ö–æ–¥–∏–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π score –¥–ª—è –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–∞
    max_score = max([entry["total"] for entry in leaderboard]) if leaderboard else 100
    
    # –†–µ–Ω–¥–µ—Ä–∏–º —à–∞–±–ª–æ–Ω
    print("–ì–µ–Ω–µ—Ä–∞—Ü–∏—è HTML...")
    env = Environment(loader=FileSystemLoader('templates'))
    template = env.get_template('leaderboard.jinja2')
    
    html_content = template.render(
        leaderboard=leaderboard,
        max_score=max_score,
        update_time=datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    )
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º
    output_file = Path("index.html")
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(html_content)
    
    print(f"‚úÖ –õ–∏–¥–µ—Ä–±–æ—Ä–¥ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω: {output_file}")
    print(f"üìä –ú–æ–¥–µ–ª–µ–π –≤ –ª–∏–¥–µ—Ä–±–æ—Ä–¥–µ: {len(leaderboard)}")
    
    # –í—ã–≤–æ–¥–∏–º —Ç–æ–ø-3
    print("\nüèÜ –¢–û–ü-3:")
    for i, entry in enumerate(leaderboard[:3], 1):
        se_str = f" ¬± {entry['total_se']:.2f}" if entry.get('total_se') else ""
        print(f"  {i}. {entry['model']}: {entry['total']:.2f}{se_str} –Ω–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–æ –æ—à–∏–±–æ–∫/1000 —Ç–æ–∫–µ–Ω–æ–≤")


if __name__ == "__main__":
    generate_leaderboard()
